{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Distributed P2P DistilGPT-2 Demo\n",
    "\n",
    "Multi-instance distributed LLM system demo.\n",
    "\n",
    "## Setup\n",
    "- Instance 1 (172.31.42.169): Shard 0 (layers 0-2)\n",
    "- Instance 2 (172.31.34.102): Shard 1 (layers 3-5)\n",
    "\n",
    "## Steps\n",
    "1. Start shards on both instances\n",
    "2. Check health and peer discovery\n",
    "3. Test distributed text generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af01182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 0: http://172.31.42.169:8000\n",
      "Shard 1: http://172.31.34.102:8000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Instance configuration\n",
    "INSTANCE_1_IP = \"172.31.42.169\"  # Shard 0\n",
    "INSTANCE_2_IP = \"172.31.34.102\"  # Shard 1\n",
    "PORT = 8000\n",
    "\n",
    "SHARD_0_URL = f\"http://{INSTANCE_1_IP}:{PORT}\"\n",
    "SHARD_1_URL = f\"http://{INSTANCE_2_IP}:{PORT}\"\n",
    "\n",
    "print(f\"Shard 0: {SHARD_0_URL}\")\n",
    "print(f\"Shard 1: {SHARD_1_URL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Start Shards\n",
    "\n",
    "**Instance 1:**\n",
    "```bash\n",
    "cd /home/ubuntu/llm_p2p\n",
    "./scripts/setup_shard1.sh\n",
    "```\n",
    "\n",
    "**Instance 2:**\n",
    "```bash\n",
    "ssh ubuntu@172.31.34.102\n",
    "cd /home/ubuntu/llm_p2p\n",
    "./scripts/setup_shard2.sh\n",
    "```\n",
    "\n",
    "Wait 30-60 seconds for model loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92781f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Check:\n",
      "Instance 1: HEALTHY - Shard 0, Layers 0-2\n",
      "Instance 2: HEALTHY - Shard 1, Layers 3-5\n",
      "Both shards ready\n"
     ]
    }
   ],
   "source": [
    "# Check shard health\n",
    "def check_health(url, name):\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"{name}: HEALTHY - Shard {data['shard_id']}, Layers {data['layers']}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"{name}: ERROR - Status {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: NOT ACCESSIBLE - {e}\")\n",
    "        return False\n",
    "\n",
    "# Check both instances\n",
    "print(\"Health Check:\")\n",
    "shard_0_ok = check_health(SHARD_0_URL, \"Instance 1\")\n",
    "shard_1_ok = check_health(SHARD_1_URL, \"Instance 2\")\n",
    "\n",
    "if shard_0_ok and shard_1_ok:\n",
    "    print(\"Both shards ready\")\n",
    "else:\n",
    "    print(\"Some shards not ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9365eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peer Discovery:\n",
      "Instance 1: Found 2 peers\n",
      "  Shard 1: 172.31.34.102:8000\n",
      "  Shard 0: 172.31.42.169:8000\n",
      "Instance 2: Found 2 peers\n",
      "  Shard 0: 172.31.42.169:8000\n",
      "  Shard 1: 172.31.34.102:8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check peer discovery\n",
    "def check_peers(url, name):\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/peers\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"{name}: Found {data['total_peers']} peers\")\n",
    "            for peer in data['peers']:\n",
    "                print(f\"  Shard {peer['shard_id']}: {peer['host']}:{peer['port']}\")\n",
    "            return len(data['peers']) > 0\n",
    "        else:\n",
    "            print(f\"{name}: Peer check failed\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: Peer check error - {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Peer Discovery:\")\n",
    "check_peers(SHARD_0_URL, \"Instance 1\")\n",
    "check_peers(SHARD_1_URL, \"Instance 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc5d9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Generation Test:\n",
      "Input: 'Hello distributed P2P'\n",
      "Output: 'Hello distributed P2P projects in the future.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'\n",
      "Time: 7.38s\n",
      "Shards used: [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_texts': ['Hello distributed P2P projects in the future.\\n\\n\\n\\n\\n'],\n",
       " 'prompt': 'Hello distributed P2P',\n",
       " 'processing_time': 7.3806798458099365,\n",
       " 'shards_used': [0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate text using distributed inference\n",
    "def generate_text(prompt, max_length=20, url=SHARD_0_URL):\n",
    "    request_data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_length\": max_length,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 50,\n",
    "        \"do_sample\": True,\n",
    "        \"repetition_penalty\": 1.1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{url}/generate\", json=request_data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"Input: '{result['prompt']}'\")\n",
    "            print(f\"Output: '{result['generated_texts'][0]}'\")\n",
    "            print(f\"Time: {result['processing_time']:.2f}s\")\n",
    "            print(f\"Shards used: {result['shards_used']}\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"Generation failed: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test generation\n",
    "print(\"Text Generation Test:\")\n",
    "generate_text(\"Hello distributed P2P\", max_length=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb2c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P Routing Test:\n",
      "Request to Instance 1:\n",
      "Input: 'P2P networks enable'\n",
      "Output: 'P2P networks enable low latency network access to high-quality content.\n",
      "\n",
      "\n",
      "'\n",
      "Time: 9.84s\n",
      "Shards used: [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "\n",
      "Request to Instance 2:\n",
      "Input: 'P2P networks enable'\n",
      "Output: 'P2P networks enable a network to communicate in the same way that a computer can communicate'\n",
      "Time: 9.80s\n",
      "Shards used: [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "\n",
      "Both instances working\n",
      "P2P auto-routing successful\n"
     ]
    }
   ],
   "source": [
    "# Test P2P routing - requests to different instances\n",
    "print(\"P2P Routing Test:\")\n",
    "\n",
    "prompt = \"P2P networks enable\"\n",
    "\n",
    "print(\"Request to Instance 1:\")\n",
    "result1 = generate_text(prompt, max_length=18, url=SHARD_0_URL)\n",
    "\n",
    "print(\"\\nRequest to Instance 2:\")\n",
    "result2 = generate_text(prompt, max_length=18, url=SHARD_1_URL)\n",
    "\n",
    "if result1 and result2:\n",
    "    print(\"\\nBoth instances working\")\n",
    "    print(\"P2P auto-routing successful\")\n",
    "else:\n",
    "    print(\"\\nSome routing failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c255c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
